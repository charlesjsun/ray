pendulum_medium_expert_dt:
    env: 'Pendulum-v1'
    run: DT
    stop:
        # We could make this -200, but given that we have 4 cpus for our tests, we will have to settle for -300.
        evaluation/episode_reward_mean: -300
        timesteps_total: 20000000
    config:
        input: 'dataset'
        input_config:         
            paths: [
                '/Users/charlesjsun/code/tmp/pendulum_expert/pendulum_expert_sac_50.json',
                '/Users/charlesjsun/code/tmp/pendulum_medium/pendulum_medium_sac_50.json',
            ]
            format: 'json'
        num_workers: 3
        actions_in_input_normalized: True
        clip_actions: True
        normalize_actions: True
        # training
        framework: torch
        train_batch_size: 512
        target_return: -150.0
        lr: 0.0
        lr_schedule: [[0, 0.0], [10000, 0.01]]
        grad_clip: 0.25
        optimizer:
            weight_decay: 0.1
#            betas: [0.9, 0.95]
            betas: [0.9, 0.999]
        replay_buffer_config:
            capacity: 20
        # model
        model:
            max_seq_len: 3
        num_heads: 1
        embed_dim: 64
        num_layers: 1
#        num_heads: 1
#        embed_dim: 64
        # rollout
        horizon: 200
        # evaluation
        evaluation_config:
            explore: False
            input: sampler
        evaluation_duration: 10
        evaluation_duration_unit: episodes
        evaluation_interval: 1
        evaluation_num_workers: 1
        evaluation_parallel_to_training: True